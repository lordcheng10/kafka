broker.id=0
log.dirs=/Users/linchen/study/kafkaData2
zookeeper.connect=localhost:2181
smart.extend.enable=true
bootstrap.servers=localhost:9092
log.retention.hours = 48
log.segment.bytes = 1932735283
unclean.leader.election.enable = true
auto.leader.rebalance.enable = false
replica.lag.time.max.ms = 180000
num.recovery.threads.per.data.dir=8
num.partitions=10
zookeeper.connection.timeout.ms = 20000
num.network.threads=160
num.io.threads=256
broker.id.generation.enable = false
auto.create.topics.enable = true
group.max.session.timeout.ms = 600000

leader.update.offset.check.interval.ms=10000
sent.offset.metadata.check.interval.ms=10000
replica.entry.isr.lst.lag.ms=21600000
replica.entry.isr.lso.lag=10000
replica.trunclog.lag=2485760
log.roll.ms=3600000
controller.socket.timeout.ms=60000
log.cleaner.enable=true


socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
log.retention.check.interval.ms = 300000
quota.producer.default = 9223372036854775807
offsets.topic.num.partitions = 160
log.flush.interval.messages = 9223372036854775807
replica.socket.receive.buffer.bytes = 65536
min.insync.replicas = 1
replica.fetch.wait.max.ms = 500
ssl.keystore.type = JKS
default.replication.factor = 2
log.preallocate = false
sasl.kerberos.principal.to.local.rules = [DEFAULT]
fetch.purgatory.purge.interval.requests = 1000
replica.socket.timeout.ms = 30000
message.max.bytes = 6291456
offsets.commit.required.acks = -1
log.flush.offset.checkpoint.interval.ms = 60000
delete.topic.enable = true
quota.window.size.seconds = 1
ssl.truststore.type = JKS
offsets.commit.timeout.ms = 5000
quota.window.num = 11
authorizer.class.name =
num.replica.fetchers = 20
log.roll.jitter.hours = 0
offsets.load.buffer.size = 5242880
log.cleaner.delete.retention.ms = 86400000
ssl.client.auth = none
controlled.shutdown.max.retries = 3
queued.max.requests = 1000
offsets.topic.replication.factor = 3
log.cleaner.threads = 1
sasl.kerberos.ticket.renew.jitter = 0.05
ssl.trustmanager.algorithm = PKIX
zookeeper.session.timeout.ms = 120000
log.retention.bytes = -1
sasl.kerberos.min.time.before.relogin = 60000
zookeeper.set.acl = false
connections.max.idle.ms = 600000
offsets.retention.minutes = 1440
replica.fetch.backoff.ms = 1000
#inter.broker.protocol.version = 0.9.0.1
#log.message.format.version = 0.9.0.1
ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
log.flush.scheduler.interval.ms = 9223372036854775807
log.index.size.max.bytes = 10485760
ssl.keymanager.algorithm = SunX509
security.inter.broker.protocol = PLAINTEXT
replica.fetch.max.bytes = 6291456
log.cleaner.dedupe.buffer.size = 134217728
replica.high.watermark.checkpoint.interval.ms = 5000
log.cleaner.io.buffer.size = 524288
sasl.kerberos.ticket.renew.window.factor = 0.8
controlled.shutdown.retry.backoff.ms = 5000
log.cleanup.policy = delete
host.name =
#max.connections.per.ip = 1024
offsets.topic.segment.bytes = 104857600
background.threads = 10
quota.consumer.default = 9223372036854775807
request.timeout.ms = 30000
log.index.interval.bytes = 4096
log.cleaner.backoff.ms = 15000
offset.metadata.max.bytes = 4096
zookeeper.sync.time.ms = 2000
port = 9092
log.segment.delete.delay.ms = 60000
controlled.shutdown.enable = true
compression.type = producer
max.connections.per.ip.overrides =
sasl.kerberos.kinit.cmd = /usr/bin/kinit
log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
leader.imbalance.check.interval.seconds = 300
log.cleaner.min.cleanable.ratio = 0.5
reserved.broker.max.id = 1000
metrics.num.samples = 2
ssl.protocol = TLS
replica.fetch.min.bytes = 1
group.min.session.timeout.ms = 6000
log.cleaner.io.buffer.load.factor = 0.9
offsets.retention.check.interval.ms = 600000
producer.purgatory.purge.interval.requests = 1000
metrics.sample.window.ms = 30000
offsets.topic.compression.codec = 0
leader.imbalance.per.broker.percentage = 10

replica.trunclog.expried.ms=3600000
message.timestamp.type=LogAppendTime